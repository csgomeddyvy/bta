import os
import discord
from discord.ext import commands
import google.generativeai as genai
import requests
import io
import time
import base64
from keep_alive import keep_alive

# --- C·∫§U H√åNH ---
DISCORD_TOKEN = os.environ.get("DISCORD_TOKEN")
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")
HF_TOKEN = os.environ.get("HF_TOKEN")  # Hugging Face Token

# C·∫•u h√¨nh Gemini
genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel('gemini-2.5-flash')

# C·∫•u h√¨nh Bot Discord
intents = discord.Intents.default()
intents.message_content = True
bot = commands.Bot(command_prefix='!', intents=intents)

# Danh s√°ch model Hugging Face ch·∫•t l∆∞·ª£ng cao
HF_MODELS = [
    "stabilityai/stable-diffusion-xl-base-1.0",  # Model c·ª±c t·ªët
    "runwayml/stable-diffusion-v1-5",            # Model ·ªïn ƒë·ªãnh
    "black-forest-labs/FLUX.1-schnell",          # Model nhanh, ch·∫•t l∆∞·ª£ng
]

def optimize_prompt_with_gemini(prompt):
    """T·ªëi ∆∞u h√≥a prompt v·ªõi Gemini ƒë·ªÉ c√≥ ch·∫•t l∆∞·ª£ng ·∫£nh t·ªët nh·∫•t"""
    try:
        response = model.generate_content(
            f"""B·∫°n l√† chuy√™n gia t·∫°o prompt AI art. H√£y chuy·ªÉn ƒë·ªïi √Ω t∆∞·ªüng sau th√†nh prompt ti·∫øng Anh ch·∫•t l∆∞·ª£ng cao cho AI v·∫Ω tranh.
            
Y√äU C·∫¶U:
- D·ªãch sang ti·∫øng Anh
- Th√™m m√¥ t·∫£ chi ti·∫øt v·ªÅ: phong c√°ch ngh·ªá thu·∫≠t, √°nh s√°ng, composition, m√†u s·∫Øc
- ƒê·ªô d√†i 50-100 t·ª´
- Bao g·ªìm t·ª´ kh√≥a ch·∫•t l∆∞·ª£ng nh∆∞: "masterpiece", "best quality", "detailed", "4K"
- Ch·ªâ tr·∫£ v·ªÅ prompt cu·ªëi c√πng, kh√¥ng th√™m gi·∫£i th√≠ch

√ù t∆∞·ªüng: {prompt}"""
        )
        return response.text.strip()
    except Exception as e:
        print(f"L·ªói t·ªëi ∆∞u prompt: {e}")
        return prompt  # Fallback v·ªÅ prompt g·ªëc

def draw_with_huggingface(prompt, model_name=HF_MODELS[0]):
    """T·∫°o ·∫£nh ch·∫•t l∆∞·ª£ng cao v·ªõi Hugging Face API"""
    API_URL = f"https://api-inference.huggingface.co/models/{model_name}"
    headers = {"Authorization": f"Bearer {HF_TOKEN}"}
    
    # Parameters cho ch·∫•t l∆∞·ª£ng cao nh·∫•t
    payload = {
        "inputs": prompt,
        "parameters": {
            "width": 1024,
            "height": 1024,
            "num_inference_steps": 30,  # TƒÉng steps ƒë·ªÉ chi ti·∫øt h∆°n
            "guidance_scale": 7.5,      # C√¢n b·∫±ng s√°ng t·∫°o v√† tu√¢n th·ªß prompt
            "negative_prompt": "blurry, low quality, worst quality, bad anatomy, watermark, signature, text, error",
        },
        "options": {
            "wait_for_model": True,     # ƒê·ª£i model n·∫øu ƒëang load
            "use_cache": True
        }
    }
    
    print(f"üîÑ ƒêang t·∫°o ·∫£nh v·ªõi model: {model_name}")
    response = requests.post(API_URL, headers=headers, json=payload)
    
    if response.status_code == 200:
        return response.content
    elif response.status_code == 503:
        # Model ƒëang loading, th·ª≠ l·∫°i sau
        print("Model ƒëang loading, th·ª≠ l·∫°i sau 10s...")
        time.sleep(10)
        return draw_with_huggingface(prompt, model_name)
    else:
        print(f"L·ªói API: {response.status_code} - {response.text}")
        return None

def draw_with_flux(prompt):
    """Fallback v·ªõi FLUX model ch·∫•t l∆∞·ª£ng cao"""
    try:
        # M√£ h√≥a prompt ƒë·ªÉ URL an to√†n
        import urllib.parse
        encoded_prompt = urllib.parse.quote(prompt)
        
        image_url = f"https://image.pollinations.ai/prompt/{encoded_prompt}?" \
                   f"model=flux&width=1024&height=1024&nologo=true&enhance=true"
        
        response = requests.get(image_url, timeout=30)
        if response.status_code == 200:
            return response.content
    except Exception as e:
        print(f"L·ªói FLUX: {e}")
    
    return None

@bot.event
async def on_ready():
    print(f'üé® Bot {bot.user} ƒë√£ s·∫µn s√†ng - Ch·∫ø ƒë·ªô Ch·∫•t L∆∞·ª£ng Cao!')
    await bot.change_presence(activity=discord.Activity(
        type=discord.ActivityType.watching, 
        name="!ve + √Ω t∆∞·ªüng | HD Art"
    ))

@bot.command(name="ve")
async def draw_image(ctx, *, prompt: str):
    """L·ªánh v·∫Ω tranh ch·∫•t l∆∞·ª£ng cao"""
    
    if not prompt:
        await ctx.send("‚ùå Vui l√≤ng cung c·∫•p m√¥ t·∫£ ƒë·ªÉ v·∫Ω tranh!\nV√≠ d·ª•: `!ve m·ªôt ch√∫ m√®o ƒëang ng·ªìi tr√™n m√¢y`")
        return
    
    # Th√¥ng b√°o ƒëang x·ª≠ l√Ω
    msg = await ctx.send(f"üé® **AI Artist** ƒëang s√°ng t·∫°o: '{prompt}'...\n‚è≥ Ch·∫•t l∆∞·ª£ng cao c√≥ th·ªÉ m·∫•t 15-30 gi√¢y...")

    try:
        # B∆Ø·ªöC 1: T·ªëi ∆∞u h√≥a prompt v·ªõi Gemini
        await msg.edit(content=f"üé® **AI Artist** ƒëang t·ªëi ∆∞u h√≥a √Ω t∆∞·ªüng...")
        optimized_prompt = optimize_prompt_with_gemini(prompt)
        
        print(f"üìù Prompt g·ªëc: {prompt}")
        print(f"üöÄ Prompt t·ªëi ∆∞u: {optimized_prompt}")

        # B∆Ø·ªöC 2: T·∫°o ·∫£nh v·ªõi Hugging Face (ch·∫•t l∆∞·ª£ng cao)
        image_data = None
        
        if HF_TOKEN:
            await msg.edit(content=f"üé® **AI Artist** ƒëang v·∫Ω v·ªõi c√¥ng ngh·ªá cao c·∫•p...")
            
            # Th·ª≠ l·∫ßn l∆∞·ª£t c√°c model ch·∫•t l∆∞·ª£ng cao
            for model_name in HF_MODELS:
                image_data = draw_with_huggingface(optimized_prompt, model_name)
                if image_data:
                    print(f"‚úÖ Th√†nh c√¥ng v·ªõi model: {model_name}")
                    break
                else:
                    print(f"‚ùå Th·∫•t b·∫°i v·ªõi model: {model_name}, th·ª≠ model ti·∫øp theo...")
                    time.sleep(2)

        # B∆Ø·ªöC 3: Fallback v·ªõi FLUX n·∫øu Hugging Face th·∫•t b·∫°i
        if not image_data:
            await msg.edit(content=f"üé® **AI Artist** ƒëang v·∫Ω v·ªõi c√¥ng ngh·ªá ti√™n ti·∫øn...")
            image_data = draw_with_flux(optimized_prompt)

        # B∆Ø·ªöC 4: G·ª≠i k·∫øt qu·∫£
        if image_data:
            # Ki·ªÉm tra k√≠ch th∆∞·ªõc file
            if len(image_data) > 25 * 1024 * 1024:  # Discord limit 25MB
                await msg.edit(content="‚ùå ·∫¢nh qu√° l·ªõn ƒë·ªÉ g·ª≠i qua Discord")
                return
            
            with io.BytesIO(image_data) as file:
                await ctx.send(
                    content=f"‚ú® **T√°c ph·∫©m ngh·ªá thu·∫≠t c·ªßa b·∫°n!**\n"
                           f"üìù **√ù t∆∞·ªüng:** {prompt}\n"
                           f"üé® **Prompt chuy√™n nghi·ªáp:** `{optimized_prompt}`",
                    file=discord.File(file, filename="masterpiece.png")
                )
            await msg.delete()
            
        else:
            await msg.edit(content="‚ùå Kh√¥ng th·ªÉ t·∫°o ·∫£nh l√∫c n√†y. Vui l√≤ng th·ª≠ l·∫°i sau ho·∫∑c thay ƒë·ªïi m√¥ t·∫£.")

    except Exception as e:
        await msg.edit(content=f"‚ùå C√≥ l·ªói x·∫£y ra: {str(e)}")
        print(f"L·ªói chi ti·∫øt: {e}")

@bot.command(name="models")
async def show_models(ctx):
    """Hi·ªÉn th·ªã c√°c model c√≥ s·∫µn"""
    models_list = "\n".join([f"‚Ä¢ {model}" for model in HF_MODELS])
    await ctx.send(f"ü§ñ **C√°c model AI c√≥ s·∫µn:**\n{models_list}")

# Gi·ªØ bot s·ªëng
keep_alive()

# Ch·∫°y bot
if DISCORD_TOKEN and GEMINI_API_KEY:
    bot.run(DISCORD_TOKEN)
else:
    print("L·ªói: Thi·∫øu Token ho·∫∑c API Key trong Environment Variables")
